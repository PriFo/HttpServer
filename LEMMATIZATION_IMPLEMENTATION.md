# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞

## –î–∞—Ç–∞: 2025-01-20

---

## ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ

### 1. –°–æ–∑–¥–∞–Ω –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Lemmatizer

**–§–∞–π–ª**: `normalization/algorithms/lemmatizer.go`

**–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å**:
```go
type Lemmatizer interface {
    Lemmatize(word string) string
    LemmatizeTokens(tokens []string) []string
    LemmatizeWithCache(word string) string
    LemmatizeText(text string) string
}
```

---

### 2. –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω RussianLemmatizer

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏**:
- ‚úÖ –°–ª–æ–≤–∞—Ä—å —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ (–º–∞—Å–ª–æ, —Å–ª–∏–≤–æ—á–Ω—ã–π, –∫–∞–±–µ–ª—å, –º–æ–ª–æ—Ç–æ–∫, –¥–µ—Ä–µ–≤–æ, —Å—Ç–∞–ª—å, –ø–ª–∞—Å—Ç–∏–∫, —Ü–≤–µ—Ç–∞)
- ‚úÖ –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö (–æ–≥–æ, –æ–º—É, —ã–º, –æ–π, —É—é, –æ–µ, —ã–µ, —ã—Ö, —ã–º–∏)
- ‚úÖ –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö (–∞, —É, –æ–º, –µ, —ã, –æ–≤, –∞–º, –∞–º–∏)
- ‚úÖ –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –≥–ª–∞–≥–æ–ª–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
- ‚úÖ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (BatchLemmatize)

**–ü—Ä–∏–º–µ—Ä—ã**:
- "–º–∞—Å–ª–∞–º–∏" ‚Üí "–º–∞—Å–ª–æ"
- "—Å–ª–∏–≤–æ—á–Ω–æ–≥–æ" ‚Üí "—Å–ª–∏–≤–æ—á–Ω—ã–π"
- "–∫–∞–±–µ–ª—è" ‚Üí "–∫–∞–±–µ–ª—å"
- "–º–æ–ª–æ—Ç–∫–æ–º" ‚Üí "–º–æ–ª–æ—Ç–æ–∫"

---

### 3. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ DuplicateAnalyzer

**–ò–∑–º–µ–Ω–µ–Ω–∏—è**:
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ `lemmatizer` –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É `DuplicateAnalyzer`
- ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ `NewDuplicateAnalyzer()`
- ‚úÖ –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ `tokenizeWithLemmatization()` –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π
- ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω `findWordBasedDuplicates()` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–ª–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ö
- –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

---

### 4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ NameNormalizer

**–ò–∑–º–µ–Ω–µ–Ω–∏—è**:
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ `lemmatizer` –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É `NameNormalizer`
- ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ `NewNameNormalizer()`
- ‚úÖ –ù–æ–≤—ã–π –º–µ—Ç–æ–¥ `NormalizeNameWithLemmatization()` –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**:
```go
normalizer := normalization.NewNameNormalizer()
normalized := normalizer.NormalizeNameWithLemmatization("–º–∞—Å–ª–∞–º–∏ —Å–ª–∏–≤–æ—á–Ω–æ–≥–æ")
// –†–µ–∑—É–ª—å—Ç–∞—Ç: "–º–∞—Å–ª–æ —Å–ª–∏–≤–æ—á–Ω—ã–π"
```

---

### 5. –¢–µ—Å—Ç—ã

**–§–∞–π–ª**: `normalization/algorithms/lemmatizer_test.go`

**–ü–æ–∫—Ä—ã—Ç–∏–µ**:
- ‚úÖ –¢–µ—Å—Ç `Lemmatize()` - –±–∞–∑–æ–≤–∞—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è
- ‚úÖ –¢–µ—Å—Ç `LemmatizeTokens()` - –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –º–∞—Å—Å–∏–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
- ‚úÖ –¢–µ—Å—Ç `LemmatizeText()` - –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- ‚úÖ –¢–µ—Å—Ç `LemmatizeSimilarity()` - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –ª–µ–º–º–∞–º
- ‚úÖ –¢–µ—Å—Ç `Cache()` - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è

**–†–µ–∑—É–ª—å—Ç–∞—Ç**: –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç ‚úÖ

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –°—Ç–µ–º–º–∏–Ω–≥ vs –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è

| –ê—Å–ø–µ–∫—Ç | –°—Ç–µ–º–º–∏–Ω–≥ | –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è |
|--------|----------|--------------|
| –¢–æ—á–Ω–æ—Å—Ç—å | –°—Ä–µ–¥–Ω—è—è | –í—ã—Å–æ–∫–∞—è |
| –ü—Ä–∏–º–µ—Ä | "–º–∞—Å–ª–∞–º–∏" ‚Üí "–º–∞—Å–ª" | "–º–∞—Å–ª–∞–º–∏" ‚Üí "–º–∞—Å–ª–æ" |
| –°–∫–æ—Ä–æ—Å—Ç—å | –ë—ã—Å—Ç—Ä–∞—è | –°—Ä–µ–¥–Ω—è—è |
| –ü–∞–º—è—Ç—å | –ù–∏–∑–∫–∞—è | –°—Ä–µ–¥–Ω—è—è (–∫—ç—à) |
| –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ | –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ | –¢–æ—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ |

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —Å—Ç–µ–º–º–∏–Ω–≥ - –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞.

---

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –£–ª—É—á—à–µ–Ω–∏—è

1. ‚úÖ **–¢–æ—á–Ω–æ—Å—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏—è** - —Å–ª–æ–≤–∞ –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ö —Ç–µ–ø–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç—Å—è
2. ‚úÖ **–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤** - —É–ª—É—á—à–µ–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞–º–∏ —Å–ª–æ–≤
3. ‚úÖ **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è** - –±–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤

### –ú–µ—Ç—Ä–∏–∫–∏

- **–ü–æ–∫—Ä—ã—Ç–∏–µ —Å–ª–æ–≤–∞—Ä—è**: ~50+ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
- **–ü—Ä–∞–≤–∏–ª–∞**: –ü—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ, —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ, –≥–ª–∞–≥–æ–ª—ã
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
- **–¢–µ—Å—Ç—ã**: 5 —Ç–µ—Å—Ç–æ–≤, –≤—Å–µ –ø—Ä–æ—Ö–æ–¥—è—Ç

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. ‚úÖ –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞
2. ‚è≥ –£–ª—É—á—à–µ–Ω–∏–µ NER (Named Entity Recognition)
3. ‚è≥ –ü—Ä–µ—Ñ–∏–∫—Å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

---

## üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –í –∫–æ–¥–µ

```go
// –°–æ–∑–¥–∞–Ω–∏–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä–∞
lem := algorithms.NewRussianLemmatizer()

// –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
lemma := lem.Lemmatize("–º–∞—Å–ª–∞–º–∏") // ‚Üí "–º–∞—Å–ª–æ"

// –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
text := lem.LemmatizeText("–º–∞—Å–ª–∞–º–∏ —Å–ª–∏–≤–æ—á–Ω–æ–≥–æ") // ‚Üí "–º–∞—Å–ª–æ —Å–ª–∏–≤–æ—á–Ω—ã–π"

// –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –ª–µ–º–º–∞–º
similarity := lem.LemmatizeSimilarity("–º–∞—Å–ª–∞–º–∏", "–º–∞—Å–ª–æ") // ‚Üí 1.0
```

### –í DuplicateAnalyzer

–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ `findWordBasedDuplicates()` –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.

### –í NameNormalizer

```go
normalizer := normalization.NewNameNormalizer()
normalized := normalizer.NormalizeNameWithLemmatization("–º–∞—Å–ª–∞–º–∏ —Å–ª–∏–≤–æ—á–Ω–æ–≥–æ")
```

---

**–°—Ç–∞—Ç—É—Å**: ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ  
**–î–∞—Ç–∞**: 2025-01-20  
**–¢–µ—Å—Ç—ã**: ‚úÖ –í—Å–µ –ø—Ä–æ—Ö–æ–¥—è—Ç

