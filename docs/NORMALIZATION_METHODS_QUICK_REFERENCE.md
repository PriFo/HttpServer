# üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –º–µ—Ç–æ–¥–∏–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ù–°–ò

## üìå –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏ –º–µ—Ç–æ–¥—ã

### 1. –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
```go
normalizer := normalization.NewNameNormalizer()
normalized := normalizer.NormalizeName("WBC00Z0002 –ö–∞–±–µ–ª—å –í–í–ì 3x2.5 120mm")
// –†–µ–∑—É–ª—å—Ç–∞—Ç: "–∫–∞–±–µ–ª—å –≤–≤–≥"
```

### 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
```go
normalized, attrs := normalizer.ExtractAttributes("WBC00Z0002 –ö–∞–±–µ–ª—å –í–í–ì 3x2.5")
// –ò–∑–≤–ª–µ–∫–∞–µ—Ç: –∞—Ä—Ç–∏–∫—É–ª—ã, —Ä–∞–∑–º–µ—Ä—ã, –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
```

### 3. –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
```go
categorizer := normalization.NewCategorizer()
category := categorizer.Categorize("–ö–∞–±–µ–ª—å –í–í–ì 3x2.5")
// –†–µ–∑—É–ª—å—Ç–∞—Ç: "–ö–∞–±–µ–ª–∏ –∏ –ø—Ä–æ–≤–æ–¥–∞"
```

### 4. –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
```go
analyzer := normalization.NewDuplicateAnalyzer()
groups := analyzer.AnalyzeDuplicates(items)
// –ù–∞—Ö–æ–¥–∏—Ç: exact, semantic, phonetic, word-based –¥—É–±–ª–∏–∫–∞—Ç—ã
```

### 5. Fuzzy Matching
```go
fuzzyMatcher := quality.NewFuzzyMatcher(db, 0.85)
duplicates := fuzzyMatcher.FindDuplicateNames(uploadID, databaseID)
// –ò—Å–ø–æ–ª—å–∑—É–µ—Ç: Levenshtein distance, –ø—Ä–µ—Ñ–∏–∫—Å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
```

### 6. AI-–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
```go
aiNormalizer := normalization.NewAINormalizer(aiConfig)
result := aiNormalizer.NormalizeWithAI(name, category)
// –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–º—è, –∫–∞—Ç–µ–≥–æ—Ä–∏—é, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ
```

## üìä –ê–ª–≥–æ—Ä–∏—Ç–º—ã

| –ê–ª–≥–æ—Ä–∏—Ç–º | –ö–ª–∞—Å—Å | –ú–µ—Ç–æ–¥ | –ü–æ—Ä–æ–≥ |
|----------|-------|-------|-------|
| Levenshtein Distance | `FuzzyMatcher` | `levenshteinDistance()` | - |
| Cosine Similarity | `DuplicateAnalyzer` | `findSemanticDuplicates()` | 0.85 |
| Phonetic Hash | `DuplicateAnalyzer` | `phoneticHash()` | 0.90 |
| Word-based Grouping | `DuplicateAnalyzer` | `findWordBasedDuplicates()` | 1 —Å–ª–æ–≤–æ |
| Exact Matching | `DuplicateAnalyzer` | `findExactDuplicatesByCode()` | 1.0 |

## üîß –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è

```go
// –ê—Ä—Ç–∏–∫—É–ª—ã: ^[a-z–∞-—è]{2,}\d+[a-z–∞-—è]*\d+\s*
// –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–¥—ã: \b[A-Z]{2}-\d+\b
// –†–∞–∑–º–µ—Ä—ã: \d+[x—Ö]\d+
// –ï–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è: \d+\.?\d*\s*(—Å–º|–º–º|–º|–ª|–∫–≥|%|–≥|–º–≥|—à—Ç|–º–ª|...)
```

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- **–û–±—Ä–∞–±–æ—Ç–∫–∞:** 500-1000 –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫
- **–ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:** –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –¥–ª—è 100K –∑–∞–ø–∏—Å–µ–π
- **Fuzzy matching:** –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –ø—Ä–µ—Ñ–∏–∫—Å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

## üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

–°–º. `docs/NORMALIZATION_METHODS_COMPLETE.md` –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤.

