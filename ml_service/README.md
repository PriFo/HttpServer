# Номенклатурный ML-сервис

Независимый Python-сервис, который обучает и обслуживает нейросеть (scikit-learn `MLPClassifier`) для классификации номенклатуры на «товар» / «услугу». Сервис включает контроль качества входных данных, feature store, мониторинг дрейфа, Explainable AI и управление метаданными модели.

## Основные возможности

- **REST API (FastAPI)** для обучения, инференса, контроля качества, мониторинга дрейфа и управления фичами/метаданными.
- **MLPClassifier** с архитектурой `512-256-128`, `relu`, `adam`, `batch_size=1024`, `learning_rate='adaptive'`, `warm_start=True`, `early_stopping=True`. Параметры подобраны для устойчивого обучения на десятках миллионов записей (поддерживается шардирование и переобучение на свежем датасете).
- **Feature store** на parquet-файлах с версионированием. Позволяет переиспользовать фичи, автоматически материализует производные признаки.
- **Data quality guard** – дешёвые проверки на пропуски, дубликаты, невалидные OKВЭД/HS коды перед запуском обучения/инференса.
- **Drift monitor** – расчёт PSI и Jensen–Shannon для числовых и категориальных признаков, хранение baseline и алерт при дрейфе.
- **Explainability** – гибридная система: глобальные permutation importances + локальные лексические объяснения («почему товар/услуга»).
- **Metadata store** – JSON-реестр версий модели, метрик и даты обучения; легко интегрируется с внутренними governance-инструментами.
- **Monitoring dashboard** – отдельное FastAPI-приложение (порт `6565`) на Jinja2/Plotly: показывает статус воркеров, метрики, БД `ml_store.db`, историю запросов и версий моделей; включает REST API (`GET /monitoring/workers/stats`, `GET /monitoring/db/status`, `GET /monitoring/requests/active`, `POST /monitoring/db/init`, `POST /monitoring/actions/*`), WebSocket `/ws/workers`, экспорт статистики и административные действия.

## Быстрый старт

```bash
cd ml_service
python -m venv .venv
.venv\Scripts\activate  # или source .venv/bin/activate
pip install -r requirements.txt
uvicorn ml_service.service:app --reload --port 8085
```

### Docker

Сервис можно запускать изолированно:

```bash
cd ml_service
docker compose up --build
```

```bash
docker build -t ml_service:test ./ml_service
docker run -d -p 6565:6565 -p 8085:8085 --name ml-service ml_service:test
```

`docker-compose.yml` резервирует 2 CPU и 8 ГБ RAM для контейнера, монтирует каталог `ml_artifacts` (артефакты модели) и, при необходимости, `data` для вспомогательных файлов, а также пробрасывает файл `ml_store.db` напрямую (`./ml_store.db:/app/ml_service/ml_store.db`). Внутри контейнера запускаются два процесса:

- `gunicorn ml_service.service:app` → основной ML API на `http://localhost:8085`
- `uvicorn ml_service.monitoring:app` → мониторинг/дашборд на `http://localhost:6565`

По умолчанию административные эндпоинты мониторинга защищены Basic Auth (`ML_MONITOR_ADMIN_USER`, `ML_MONITOR_ADMIN_PASSWORD`, дефолт `admin/admin`). UI автоматически обновляется каждые 10 секунд, дополнительно есть WebSocket `/ws/workers`.

В production можно масштабировать горизонтально (`docker compose up --scale ml-service=3`) или в Kubernetes, использовав `resources.requests/limits` и autoscaler.

#### SQLite-хранилище в контейнере

Схема находится в `sql/sqlite_schema.sql` и покрывает хранение датасетов, их версий, пользовательских правок и моделей. Файл `ml_store.db` уже лежит в корне репозитория и автоматически копируется/монтируется в контейнер (`./ml_store.db:/app/ml_service/ml_store.db`). При необходимости пересоздать схему:

```bash
cd ml_service
sqlite3 ml_store.db < sql/sqlite_schema.sql
# или
python -c "import sqlite3, pathlib; schema=pathlib.Path('sql/sqlite_schema.sql').read_text(); conn=sqlite3.connect('ml_store.db'); conn.executescript(schema); conn.close()"
```

- `datasets`, `dataset_versions`, `dataset_items` — полный слепок выгрузок и их версий.
- `user_updates` — правки от пользователей для последующего дообучения.
- `training_jobs` + `models` — история запусков обучения и пути к артефактам.
- `predictions_log` — журнал запросов/ответов, если потребуется трассировка.

Файл `ml_store.db` лежит рядом с кодом и переживает перезапуск контейнера; application-код обращается к нему как `sqlite:////app/ml_service/ml_store.db`.

### Пример вызовов

1. **Обучение**

```http
POST /train
{
  "version": "v1.0.0",
  "refresh_baseline": true,
  "data": [
    {
      "name": "Поставка серверов",
      "full_name": "Поставка серверов Dell PowerEdge",
      "kind": "оборудование",
      "unit": "шт",
      "type_hint": "товар",
      "okved_code": "46.51",
      "hs_code": "8471",
      "label": "product"
    }
  ]
}
```

Если поле `data` опущено (или пустое), сервис использует `ml_service/datasets/train_dataset.csv` как основной набор для переобучения. Перед первым запуском убедитесь, что файл существует; иначе `/train` вернёт:

```
"Нет данных для обучения, перед первым использованием необходимо загрузить в блок data датасет для обучения"
```

2. **Инференс**

```http
POST /predict
{
  "top_k": 2,
  "explain": true,
  "items": [
    {
      "name": "Услуги аутсорсинга ИТ",
      "full_name": "Пакет услуг по аутсорсингу ИТ-инфраструктуры",
      "kind": "услуга",
      "unit": "компл",
      "okved_code": "62.01"
    }
  ]
}
```

3. **Контроль качества**

```http
POST /quality
{ "items": [ ... ] }
```

4. **Дрейф**

```http
POST /drift/check
{ "items": [ ... ] }
```

## Структура

| Модуль | Описание |
| --- | --- |
| `config.py` | Pydantic-настройки сервиса и путей артефактов |
| `schemas.py` | Pydantic-схемы API |
| `model.py` | Обучение/инференс MLP, сохранение/загрузка |
| `feature_store.py` | Материализация признаков и версионирование |
| `data_quality.py` | Контроль качества входных данных |
| `drift_monitor.py` | Подготовка baseline и отчётов по дрейфу |
| `dataset_manager.py` | Управление эталонным датасетом и смешивание с клиентскими |
| `explainability.py` | Глобальные/локальные объяснения |
| `metadata.py` | Управление метаданными модели |
| `regional_validation.py` | Проверки кодировок, регионов, юрисдикций |
| `priority_scheduler.py` | Очередь с приоритетами для конкурирующих запросов |
| `monitoring/` | Веб-интерфейс и REST API мониторинга (FastAPI + Jinja2 + Plotly) |
| `service.py` | FastAPI-приложение |

## Дообучение и масштабирование

- **Warm start:** `MLPClassifier` сохраняет веса и допускает переобучение на полном датасете (через повторный вызов `/train`). Для сверхбольших данных используйте feature store + батчевую прогрузку (питание моделях через `settings.max_training_rows`).
- **Версионирование:** каждая итерация `/train` сохраняет `.joblib` под уникальной версией, плюс parquet features и baseline. Линейка версий доступна через `/metadata` и `/features`.
- **Monitoring:** `drift_monitor` сигнализирует, когда PSI>0.2 или Jensen-Shannon>0.3, что является поводом для переобучения.

## Метаданные и Explainability

- Метаданные (`metadata.json`) хранят историю метрик и позволяют прикреплять заметки (например, ссылка на тикет с обучением).
- Локальные объяснения – это комбинация:
  - конфиденса модели,
  - совпадений по лексическим словарям (товар/услуга),
  - ссылок на глобальную наиболее важную фичу (перестановочная важность).

## Данные и качество

- Сервис жестко требует наличие `name` и `full_name`.
- Перед обучением каждую выгрузку следует прогонять через `/quality`. При наличии критических ошибок ответ 422 с конкретными полями.
- Feature store и baseline-дрейф позволяют вернуться к старой версии данных и сравнить распределения.
- Папка `ml_service/datasets` хранит основной CSV `train_dataset.csv`. Любой вызов `/train` сначала валидирует и подмешивает этот файл, а затем — опциональный блок `data`. Все ошибки валидации возвращаются одним ответом 422.

### Сбор эталонного датасета

Каталог `ml_service/datasets` содержит разные CSV/Excel-выгрузки (train/valid/sample и т.д.). Нормализовать их в единый набор можно одной командой:

```
python -m ml_service.data.dataset_builder ^
  --dataset-dir ml_service/datasets ^
  --output-parquet ml_artifacts/reference_dataset.parquet ^
  --output-csv ml_service/datasets/nomenclature_master.csv
```

Скрипт:

- распознаёт кодировку и разделитель каждого файла;
- приводит данные к схеме `NomenclatureItem`, чистит пробелы и заполняет обязательные поля;
- нормализует метки (`товар/услуга` → `product/service`) и удаляет дубликаты;
- сохраняет parquet/CSV и печатает JSON-сводку, где видно, сколько строк попало из каждого файла и какие выгрузки пришлось пропустить.

Полученный parquet-файл автоматически подхватывается `ReferenceDatasetManager` (см. `settings.reference_dataset_path`) и подходит для офлайн-обучения/валидации.

## Управление метаданными

- `GET /metadata` – текущее состояние + история.
- При обучении автоматически сохраняются метрики `accuracy`, `f1_macro`, `avg_confidence`.
- Можно добавлять дополнительные поля в `MetadataStore` (например, ответственный инженер, ссылка на датасет) – структура JSON расширяема.

## Обращение к модели и очереди запросов

1. **Лёгкие/синхронные кейсы:** внешние сервисы бьют напрямую по `POST /predict`. Благодаря `gunicorn` + нескольким воркерам сервис обрабатывает десятки запросов параллельно (по сути, по количеству воркеров). Для 2 CPU оптимально держать 3–4 воркера, 2–4 потока и включить keep-alive.
2. **Приоритетное обслуживание:** в самом FastAPI теперь есть встроенный приоритетный шедулер (`PriorityScheduler`). Каждый запрос к `/predict` получает вес в зависимости от полноты данных (наличие `full_name`, `kind`, кодов ОКВЭД/ТНВЭД, длины названия). Запросы с большим количеством информации попадают в начало очереди, а воркеры (числом `ML_PRIORITY_WORKERS`, по умолчанию 4) обрабатывают их первыми. Это гарантирует, что самые “богатые” записи классифицируются раньше, даже если одновременно пришло много запросов.
3. **Смешивание эталонных и клиентских данных:** `ReferenceDatasetManager` хранит канонический датасет в `ml_artifacts/reference_dataset.parquet`. На этапе `/train` входные данные перемешиваются с эталоном, при необходимости эталон реплицируется, чтобы занимать ≥10 % итоговой выборки. После успешного обучения свежие проверенные данные добавляются в эталон. Это защищает модель от размывания и сохраняет устойчивость к шуму.
4. **Региональная валидация и кодировки:** `RegionalValidator` проверяет ISO-коды стран, НС/ОКВЭД, а также допустимые кодировки (только UTF‑8). Ошибочные записи блокируются до обучения/инференса. При необходимости можно расширить списки стран/юрисдикций.
5. **Мониторинг очереди и воркеров:** `MonitoringStore` автоматически логирует каждый запрос (`train/predict/quality/drift`), фиксирует снапшоты воркеров (активные/очередь/ошибки + CPU/RAM), предоставляет API `GET /monitoring/workers/stats`, `GET /monitoring/requests/active`, WebSocket `/ws/workers` и UI на `http://localhost:6565`. Админ-панель даёт кнопку инициализации БД, остановку запросов, очистку логов и экспорт CSV/JSON.
6. **Пакетная нормализация / 100+ одновременных обращений:** рекомендуется ставить промежуточную очередь (RabbitMQ, Redis Streams, Kafka). Нормализационный сервис кладёт задания (id записи + полезная нагрузка) в очередь, `ml-service` поднимает пул воркеров (Celery/RQ/любой consumer), которые забирают задания, вызывают локальный FastAPI-инстанс (или напрямую `NomenclatureClassifier`) и сохраняют результаты в БД. Таким образом:
   - нагрузка распределяется, воркеры подтягивают задания в меру свободных CPU,
   - при падении приложения задания остаются в очереди и будут обработаны после перезапуска,
   - можно динамически увеличивать количество воркеров без изменения API.
7. **Downtime и надёжность:** используйте внешний персистентный брокер (RabbitMQ с durable очередями, Kafka, SQS). Это гарантирует, что при перезапуске контейнера никакой запрос не потеряется. Для гарантированной доставки включите подтверждения (`ack`) после успешной записи результата.
8. **Идемпотентность:** сохраняйте входные запросы/ответы в `service.db` (или другом персистентном хранилище) с idempotency key. При повторной доставке worker сверит, что ответ уже рассчитан.
9. **Backpressure:** лимитируйте размер очереди и/или используйте rate limiting на входном API, чтобы модель не «согнулась». В крайнем случае запросы можно временно парковать в брокере, а worker’ы будут по одной записи извлекать.

Таким образом, FastAPI остаётся удобной фронтовой обвязкой, но реальные батчи можно гонять через очередь + воркерный слой, обеспечивая устойчивость и отсутствие потерь при простойке.

## CLI для взаимодействия с моделью

Для ручных проверок и интеграции без Postman добавлен вспомогательный скрипт:

```
python -m ml_service.scripts.model_cli train --dataset ml_service/datasets/nomenclature_master.csv --version mlp_v1
python -m ml_service.scripts.model_cli predict --dataset ml_service/datasets/sample_dataset.csv --top-k 2 --explain
python -m ml_service.scripts.model_cli predict --json payload.json --base-url http://localhost:8085
```

Флаги `--limit`, `--refresh-baseline`, `--base-url` и `--timeout` позволяют управлять размером батча, обновлением drfit-baseline и адресом сервиса. Скрипт сам нормализует исходные данные к `NomenclatureItem`, поэтому ему можно скармливать и CSV, и заранее подготовленный JSON.

## Дальнейшие шаги

- Подключить централизованное хранилище (PostgreSQL/ClickHouse) вместо файловых артефактов.
- Завести пайплайн CI/CD для автоматического прогона `/quality` + `/train` в sandbox.
- Интегрировать сервис в существующий Go-бэкенд по HTTP/gRPC.

