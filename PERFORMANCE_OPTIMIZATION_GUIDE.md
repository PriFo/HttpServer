# Руководство по использованию оптимизаций производительности

## Обзор

Реализованы критические оптимизации производительности для процессов нормализации контрагентов. Этот документ описывает, как использовать новые возможности и измерять улучшения.

## Реализованные оптимизации

### 1. Batch Insert для контрагентов

**Что изменилось:**
- Вместо N отдельных INSERT запросов используется batch insert с транзакцией
- Контрагенты накапливаются в пакеты по 100 записей (константа `BatchSize`)
- Отдельная горутина для batch сохранения

**Как это работает:**
- Воркеры отправляют нормализованных контрагентов в канал `batchChan`
- Отдельная горутина накапливает их и сохраняет пакетами
- При достижении `BatchSize` (100) или в конце обработки выполняется batch insert

**Ожидаемое улучшение:** 40-60% сокращение времени для операций сохранения

---

### 2. In-Memory Map для поиска эталонов

**Что изменилось:**
- Все эталоны проекта загружаются один раз в начале `ProcessNormalization`
- Глобальные эталоны загружаются параллельно для всех найденных taxID
- Создается `benchmarkMap map[string]*database.ClientBenchmark` для O(1) lookup
- `FindBenchmarkByTaxID` использует map вместо запросов к БД

**Как это работает:**
1. В начале `ProcessNormalization` загружаются все эталоны проекта
2. Извлекаются все taxID (ИНН/БИН) из контрагентов
3. Глобальные эталоны загружаются параллельно для всех taxID
4. Все эталоны сохраняются в `benchmarkMap`
5. `FindBenchmarkByTaxID` использует map для мгновенного поиска

**Ожидаемое улучшение:** 20-30% сокращение времени для операций поиска эталонов

---

### 3. Динамическое количество воркеров

**Что изменилось:**
- Количество воркеров теперь зависит от `runtime.NumCPU()`
- Формула: `min(runtime.NumCPU() * 2, totalItems, MaxWorkerCount)`
- `MaxWorkerCount = 50` для ограничения максимума
- Минимум 2 воркера для малых объемов

**Как это работает:**
- Функция `calculateWorkerCount` использует `runtime.NumCPU()` для определения базового количества
- Умножает на 2 для оптимального использования CPU
- Ограничивает максимумом и минимумом

**Ожидаемое улучшение:** 10-20% улучшение на многоядерных системах

---

### 4. Оптимизация проверки остановки

**Что изменилось:**
- `StopCheckInterval` увеличен с 10 до 50
- Снижение contention на мьютексе при высокой нагрузке

**Ожидаемое улучшение:** 2-5% улучшение при высокой нагрузке

---

## Использование бенчмарков

### Запуск бенчмарков

```bash
# Все бенчмарки
go test -bench=. -benchmem ./normalization

# Конкретный бенчмарк
go test -bench=BenchmarkProcessNormalization_10K -benchmem ./normalization

# С несколькими итерациями для статистики
go test -bench=BenchmarkProcessNormalization_10K -benchmem -count=5 ./normalization
```

### Доступные бенчмарки

#### Бенчмарки полной нормализации:
- `BenchmarkProcessNormalization_1K` - 1,000 записей
- `BenchmarkProcessNormalization_10K` - 10,000 записей
- `BenchmarkProcessNormalization_50K` - 50,000 записей
- `BenchmarkProcessNormalization_100K` - 100,000 записей

#### Бенчмарки подпроцессов:
- `BenchmarkDuplicateAnalysis_*` - поиск дубликатов
- `BenchmarkDataExtraction_*` - извлечение данных
- `BenchmarkBenchmarkLookup_*` - поиск эталонов
- `BenchmarkNormalizeCounterparty_*` - нормализация одного контрагента

#### Специальные бенчмарки:
- `BenchmarkProcessNormalization_Parallel` - параллельная обработка
- `BenchmarkWorkerCount_Comparison` - сравнение разных количеств воркеров

### Использование скриптов

```bash
# Полный набор тестов производительности
bash scripts/run_performance_tests.sh

# Сравнение результатов
bash scripts/compare_benchmarks.sh BenchmarkProcessNormalization_10K
```

---

## Профилирование с pprof

### Настройка pprof эндпоинта

Если эндпоинт `/debug/pprof/` не доступен, добавьте в `server/server.go`:

```go
import _ "net/http/pprof"

// В setupMux():
mux.HandleFunc("/debug/pprof/", func(w http.ResponseWriter, r *http.Request) {
    http.DefaultServeMux.ServeHTTP(w, r)
})
```

### CPU профилирование

```bash
# Генерация CPU профиля (30 секунд)
go tool pprof http://localhost:9999/debug/pprof/profile?seconds=30

# Или используйте скрипт
bash scripts/profile_normalization.sh
```

### Memory профилирование

```bash
# Генерация Memory профиля
go tool pprof http://localhost:9999/debug/pprof/heap
```

### Анализ профилей

```bash
# Интерактивный режим
go tool pprof cpu_profile.pb.gz

# Команды в интерактивном режиме:
# top10          - Топ-10 функций по времени CPU
# web            - Визуализация в браузере
# list FunctionName - Детали конкретной функции
# png            - Сохранить график в PNG
```

---

## Сравнение результатов

### Использование benchstat

```bash
# Установка benchstat
go install golang.org/x/perf/cmd/benchstat@latest

# Сравнение двух наборов результатов
benchstat before.txt after.txt

# Статистика одного набора
benchstat results.txt
```

### Ручное сравнение

1. Запустите бенчмарки до оптимизаций:
```bash
go test -bench=BenchmarkProcessNormalization_10K -benchmem -count=5 ./normalization > before.txt
```

2. Запустите бенчмарки после оптимизаций:
```bash
go test -bench=BenchmarkProcessNormalization_10K -benchmem -count=5 ./normalization > after.txt
```

3. Сравните результаты:
```bash
benchstat before.txt after.txt
```

---

## Мониторинг производительности в production

### Метрики для отслеживания

1. **Время обработки** - общее время нормализации
2. **Скорость обработки** - записей в секунду
3. **Использование CPU** - процент использования процессора
4. **Использование памяти** - пиковое использование памяти
5. **Количество воркеров** - фактическое количество используемых воркеров

### Логирование

Все оптимизации логируют метрики:
- Количество загруженных эталонов
- Размер batch при сохранении
- Количество воркеров
- Скорость обработки (записей/сек)

### События нормализации

Структурированные события содержат метрики производительности:
- `processing_started` - начало обработки с количеством воркеров
- `progress` - прогресс с метриками
- `completed` - завершение с итоговыми метриками

---

## Рекомендации по настройке

### Размер batch

Константа `BatchSize = 100` оптимизирована для большинства случаев. Для настройки:

- **Увеличить** (200-500) - для систем с быстрой БД и большим объемом памяти
- **Уменьшить** (50) - для систем с ограниченной памятью

### Количество воркеров

Автоматически настраивается на основе CPU. Для ручной настройки измените `MaxWorkerCount`:

- **Увеличить** (100) - для систем с очень быстрой БД
- **Уменьшить** (20-30) - для систем с медленной БД или ограниченными ресурсами

### Интервал проверки остановки

`StopCheckInterval = 50` оптимизирован для баланса между отзывчивостью и производительностью:

- **Увеличить** (100) - для максимальной производительности
- **Уменьшить** (20-30) - для более быстрой реакции на остановку

---

## Устранение неполадок

### Медленная работа после оптимизаций

1. Проверьте размер batch - возможно, нужно уменьшить
2. Проверьте количество воркеров - возможно, слишком много для вашей БД
3. Проведите профилирование для выявления узких мест

### Высокое использование памяти

1. Уменьшите `BatchSize`
2. Уменьшите `MaxWorkerCount`
3. Проверьте размер `benchmarkMap` - возможно, слишком много эталонов

### Ошибки batch insert

1. Проверьте логи на наличие ошибок БД
2. Убедитесь, что транзакции не слишком длинные
3. Проверьте размер пакета - возможно, нужно уменьшить

---

## Дополнительные улучшения

### Потенциальные оптимизации

1. **Connection pooling** - настройка пула соединений SQLite
2. **LRU кэш для эталонов** - кэширование часто используемых эталонов
3. **Параллельная обработка БД** - убедиться, что разные БД обрабатываются параллельно
4. **Оптимизация extractors** - проверка производительности извлечения атрибутов

---

## Контакты и поддержка

При возникновении проблем с производительностью:
1. Запустите профилирование с pprof
2. Соберите метрики из логов
3. Запустите бенчмарки для воспроизведения проблемы
4. Создайте issue с собранными данными

---

**Дата создания:** 2025-01-XX  
**Версия:** 1.0

