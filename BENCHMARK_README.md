# Бенчмарк нормализации контрагентов

Набор инструментов для тестирования производительности системы нормализации контрагентов.

## Инструменты

### 1. test_normalization_benchmark.go

Основной бенчмарк для измерения производительности нормализации.

#### Использование

```bash
# Базовый запуск (1000 записей, 20% дубликатов, 10 воркеров)
go run test_normalization_benchmark.go

# С настройками
go run test_normalization_benchmark.go -records 5000 -duplicate-rate 0.3 -workers 16

# С тестом остановки
go run test_normalization_benchmark.go -test-stop -stop-after 500

# Комбинированный запуск
go run test_normalization_benchmark.go -records 10000 -duplicate-rate 0.25 -workers 20 -test-stop -stop-after 2000
```

#### Параметры

- `-records` - количество записей для тестирования (по умолчанию: 1000)
- `-duplicate-rate` - процент дубликатов от 0.0 до 1.0 (по умолчанию: 0.2)
- `-workers` - количество воркеров для параллельной обработки (по умолчанию: 10)
- `-test-stop` - включить тест механизма остановки
- `-stop-after` - остановить после N записей (только с `-test-stop`)
- `-cpuprofile` - сохранить CPU профиль в файл (для анализа с go tool pprof)
- `-memprofile` - сохранить memory профиль в файл (для анализа с go tool pprof)

#### Результаты

Бенчмарк создает три файла:

1. **JSON отчет** (`normalization_benchmark_YYYYMMDD_HHMMSS.json`)
   - Детальные метрики в формате JSON
   - Подходит для программной обработки

2. **HTML отчет** (`normalization_benchmark_YYYYMMDD_HHMMSS.html`)
   - Визуализация результатов
   - Таблицы с метриками
   - Статистика и рекомендации

3. **CSV отчет** (`normalization_benchmark_YYYYMMDD_HHMMSS.csv`)
   - Табличные данные для анализа в Excel/Google Sheets
   - Удобен для построения графиков

#### Измеряемые метрики

- **Время выполнения** - общее время и время по этапам
- **Скорость обработки** - записей в секунду
- **Использование памяти** - МБ для каждого этапа
- **Дубликаты** - количество найденных групп и дубликатов
- **Эталоны** - совпадения, обогащения, созданные эталоны
- **Ошибки** - количество ошибок при обработке

### 2. compare_benchmark_results.go

Утилита для сравнения результатов разных запусков бенчмарка.

### 3. analyze_benchmark.go

Утилита для автоматического анализа узких мест в производительности.

#### Использование

```bash
# Базовое сравнение
go run compare_benchmark_results.go -baseline baseline.json -current current.json

# С сохранением результата
go run compare_benchmark_results.go -baseline baseline.json -current current.json -output comparison.json
```

#### Параметры

- `-baseline` - путь к базовому JSON отчету (обязательно)
- `-current` - путь к текущему JSON отчету (обязательно)
- `-output` - путь к файлу для сохранения сравнения (опционально)

### 3. analyze_benchmark.go

Утилита для автоматического анализа узких мест в производительности.

#### Использование

```bash
# Анализ узких мест
go run analyze_benchmark.go -report normalization_benchmark_20250120_120000.json

# С сохранением результата
go run analyze_benchmark.go -report normalization_benchmark_20250120_120000.json -output analysis.json
```

#### Параметры

- `-report` - путь к JSON отчету бенчмарка (обязательно)
- `-output` - путь к файлу для сохранения анализа (опционально)

#### Результаты

Утилита автоматически:
- Определяет этапы, занимающие больше всего времени
- Классифицирует узкие места по серьезности (critical, high, medium, low)
- Генерирует рекомендации по оптимизации
- Анализирует использование памяти и скорость обработки

#### Результаты сравнения

Утилита выводит:

- **Общую статистику** - сравнение общей скорости обработки
- **Детальное сравнение** - изменения по каждому этапу
- **Рекомендации** - улучшения и ухудшения производительности

Пример вывода:

```
=== СРАВНЕНИЕ РЕЗУЛЬТАТОВ ===

Базовый отчет: 2025-01-20T10:00:00Z (1000 записей, 20.0% дубликатов)
Текущий отчет: 2025-01-20T11:00:00Z (1000 записей, 20.0% дубликатов)

Общая скорость: 45.23 -> 52.15 записей/сек (изменение: +15.30%)
  ✓ Улучшение на 15.30%

Детальное сравнение по этапам:
----------------------------------------------------------------------------
Этап                          | Скорость    | Время        | Память      | Статус
----------------------------------------------------------------------------
Data Extraction               | +12.50%     | -11.11%      | +5.00%      | ✓ Улучшение
Duplicate Detection           | +8.33%      | -7.69%       | -2.00%      | ✓ Улучшение
Full Normalization            | +20.00%     | -16.67%      | +10.00%     | ✓ Улучшение
```

## Примеры использования

### Сценарий 1: Базовое тестирование

```bash
# Запускаем бенчмарк с настройками по умолчанию
go run test_normalization_benchmark.go

# Результаты сохраняются в:
# - normalization_benchmark_20250120_120000.json
# - normalization_benchmark_20250120_120000.html
# - normalization_benchmark_20250120_120000.csv
```

### Сценарий 2: Тестирование производительности

```bash
# Тестируем с большим объемом данных
go run test_normalization_benchmark.go -records 10000 -workers 20

# Анализируем результаты в HTML отчете
```

### Сценарий 3: Сравнение до и после оптимизации

```bash
# Запускаем бенчмарк до оптимизации
go run test_normalization_benchmark.go -records 5000 > baseline_output.txt

# Сохраняем имя файла отчета
BASELINE=$(ls -t normalization_benchmark_*.json | head -1)

# ... делаем оптимизации ...

# Запускаем бенчмарк после оптимизации
go run test_normalization_benchmark.go -records 5000 > current_output.txt

# Сохраняем имя файла отчета
CURRENT=$(ls -t normalization_benchmark_*.json | head -1)

# Сравниваем результаты
go run compare_benchmark_results.go -baseline $BASELINE -current $CURRENT -output comparison.json
```

### Сценарий 4: Тестирование механизма остановки

```bash
# Тестируем остановку после 1000 записей
go run test_normalization_benchmark.go -records 5000 -test-stop -stop-after 1000

# Проверяем в отчете:
# - Время до остановки
# - Задержка остановки
# - Количество обработанных записей
```

## Интерпретация результатов

### Скорость обработки

- **> 100 записей/сек** - отличная производительность
- **50-100 записей/сек** - хорошая производительность
- **20-50 записей/сек** - приемлемая производительность
- **< 20 записей/сек** - требуется оптимизация

### Использование памяти

- **< 100 МБ** - низкое использование
- **100-500 МБ** - нормальное использование
- **500-1000 МБ** - высокое использование
- **> 1000 МБ** - требуется оптимизация

### Процент дубликатов

- **0-10%** - низкий уровень дубликатов
- **10-30%** - нормальный уровень
- **30-50%** - высокий уровень
- **> 50%** - критический уровень (требуется очистка данных)

## Рекомендации по оптимизации

### Если скорость низкая:

1. Увеличьте количество воркеров (`-workers`)
2. Проверьте использование памяти (может быть нехватка)
3. Оптимизируйте алгоритмы поиска дубликатов
4. Используйте кэширование для часто используемых данных

### Если память высокая:

1. Уменьшите размер батчей обработки
2. Используйте streaming для больших объемов
3. Очищайте промежуточные данные
4. Проверьте утечки памяти

### Если много дубликатов:

1. Улучшите алгоритмы поиска дубликатов
2. Используйте индексы для быстрого поиска
3. Применяйте предварительную фильтрацию
4. Рассмотрите использование внешних сервисов обогащения

## Структура отчетов

### JSON отчет

```json
{
  "timestamp": "2025-01-20T12:00:00Z",
  "test_name": "Normalization Performance Benchmark",
  "record_count": 1000,
  "duplicate_rate": 0.2,
  "workers": 10,
  "results": [
    {
      "stage": "Data Extraction",
      "record_count": 1000,
      "duration_ms": 500,
      "records_per_second": 2000.0,
      "memory_used_mb": 50.5
    }
  ],
  "summary": {
    "total_stages": 4,
    "average_speed": 150.5
  }
}
```

### CSV отчет

Структура колонок:
- Этап
- Записей
- Время (мс)
- Скорость (записей/сек)
- Память (МБ)
- Групп дубликатов
- Всего дубликатов
- Обработано
- Совпадений с эталонами
- Обогащено
- Создано эталонов
- Ошибок
- Остановлено

## Интеграция в CI/CD

Пример для GitHub Actions:

```yaml
- name: Run normalization benchmark
  run: |
    go run test_normalization_benchmark.go -records 1000 > benchmark_output.txt
    BENCHMARK_FILE=$(ls -t normalization_benchmark_*.json | head -1)
    echo "BENCHMARK_FILE=$BENCHMARK_FILE" >> $GITHUB_ENV

- name: Upload benchmark results
  uses: actions/upload-artifact@v3
  with:
    name: benchmark-results
    path: |
      normalization_benchmark_*.json
      normalization_benchmark_*.html
      normalization_benchmark_*.csv
```

## Устранение неполадок

### Ошибка: "Failed to create ServiceDB"

Убедитесь, что у вас есть права на создание временных файлов.

### Ошибка: "Out of memory"

Уменьшите количество записей (`-records`) или увеличьте доступную память.

### Медленная работа

- Уменьшите количество записей для тестирования
- Увеличьте количество воркеров
- Проверьте нагрузку на систему

## Профилирование производительности

### CPU профилирование

```bash
# Запуск с CPU профилированием
go run test_normalization_benchmark.go -records 5000 -cpuprofile cpu.prof

# Анализ CPU профиля
go tool pprof cpu.prof
# В интерактивном режиме:
# (pprof) top10          # Топ-10 функций по времени CPU
# (pprof) web            # Визуализация в браузере
# (pprof) list FunctionName  # Детали конкретной функции
```

### Memory профилирование

```bash
# Запуск с memory профилированием
go run test_normalization_benchmark.go -records 5000 -memprofile mem.prof

# Анализ memory профиля
go tool pprof mem.prof
# В интерактивном режиме:
# (pprof) top10          # Топ-10 функций по использованию памяти
# (pprof) web            # Визуализация в браузере
# (pprof) list FunctionName  # Детали конкретной функции
```

### Комбинированное профилирование

```bash
# Одновременное CPU и memory профилирование
go run test_normalization_benchmark.go \
  -records 5000 \
  -cpuprofile cpu.prof \
  -memprofile mem.prof
```

## Дополнительные ресурсы

- Документация по нормализации: `docs/NORMALIZATION_METHODS_COMPLETE.md`
- Алгоритмы нормализации: `normalization/NORMALIZATION_ALGORITHMS_README.md`
- Тесты производительности: `normalization/counterparty_normalizer_bench_test.go`

